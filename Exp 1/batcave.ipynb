{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.concept import TCAV, BTCAV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import IterableDataset\n",
    "from typing import Iterator\n",
    "from captum.concept._utils.data_iterator import dataset_to_dataloader\n",
    "from captum.concept import TCAV, BTCAV\n",
    "from captum.concept import Concept\n",
    "from captum.attr import LayerGradientXActivation, LayerIntegratedGradients\n",
    "from captum.concept._utils.data_iterator import dataset_to_dataloader, CustomIterableDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.concept._utils.common import concepts_to_str\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import os, shutil\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from captum.concept._utils.classifier import Classifier\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "\n",
    "# Local imports\n",
    "from batcave.BayesianLogistic import VBLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cav_folder():\n",
    "    print(\"Removing cav folder\")\n",
    "    if os.path.exists('cav'):\n",
    "        shutil.rmtree('cav')\n",
    "\n",
    "def get_tensor_from_filename(filename):\n",
    "    img = Image.open(filename).convert(\"RGB\")\n",
    "    return test_transform(img).to(device)\n",
    "\n",
    "def load_image_tensors(class_name, root_path='dataset/general blocked unblocked/test', transform=True):\n",
    "    path = os.path.join(root_path, class_name)\n",
    "    filenames = glob.glob(path + '/*.jpg')\n",
    "\n",
    "    tensors = []\n",
    "    for filename in filenames:\n",
    "        img = Image.open(filename).convert('RGB')\n",
    "        tensors.append(test_transform(img) if transform else img)\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "def assemble_concept(name, id, concepts_path=\"concepts/\"):\n",
    "    concept_path = os.path.join(concepts_path, name) + \"/\"\n",
    "    dataset = CustomIterableDataset(get_tensor_from_filename, concept_path)\n",
    "    concept_iter = dataset_to_dataloader(dataset)\n",
    "\n",
    "    return Concept(id=id, name=name, data_iter=concept_iter)\n",
    "\n",
    "\n",
    "def format_float(f):\n",
    "    return float('{:.3f}'.format(f) if abs(f) >= 0.0005 else '{:.3e}'.format(f))\n",
    "\n",
    "def extract_btcav_scores(experimental_sets, tcav_scores, layers):\n",
    "\n",
    "    ex_sets, cons, vals = [], [], []\n",
    "    for idx_es, concepts in enumerate(experimental_sets):\n",
    "\n",
    "        concepts = experimental_sets[idx_es]\n",
    "        concepts_key = concepts_to_str(concepts)\n",
    "        \n",
    "        for i in range(len(concepts)):\n",
    "            vals_j = []\n",
    "            for j in range(len(tcav_scores)):\n",
    "                val = [format_float(scores['sign_count'][i]) for layer, scores in tcav_scores[j][concepts_key].items()]\n",
    "                vals_j.append(val)\n",
    "            ex_sets.append(idx_es)\n",
    "            cons.append(concepts[i].name)\n",
    "            vals.append(vals_j)\n",
    "\n",
    "    return ex_sets, cons, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassifier(Classifier):\n",
    "    def __init__(self):\n",
    "        # self.lm = linear_model.LogisticRegression(max_iter=1000)\n",
    "        self.lm = VBLogisticRegression(fit_intercept=False)  # We artificially add an intercept below\n",
    "        self.test_size = 0.33\n",
    "        self.evaluate_test = False\n",
    "        self.metrics = None\n",
    "\n",
    "    def train_and_eval(self, dataloader: DataLoader, **kwargs):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        inputs, labels = [], []\n",
    "        for X, y in dataloader:\n",
    "            X = torch.cat((torch.ones((X.shape[0], 1), device=device), X.to(device)), dim=1)  # Add the intercept term. This is required only for the cav classifier.\n",
    "            inputs.append(X)\n",
    "            labels.append(y.to(device))\n",
    "        \n",
    "        # Move tensors to CPU before converting to NumPy\n",
    "        inputs = torch.cat(inputs).detach().cpu().numpy()\n",
    "        labels = torch.cat(labels).detach().cpu().numpy()\n",
    "        \n",
    "        if self.evaluate_test:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=self.test_size)\n",
    "        else:\n",
    "            X_train, y_train = inputs, labels\n",
    "        \n",
    "        self.lm.fit(X_train, y_train)\n",
    "\n",
    "        if self.evaluate_test:\n",
    "            self.metrics = {'accs': self.lm.score(X_test, y_test)}\n",
    "            return self.metrics\n",
    "        self.metrics = {'accs': self.lm.score(X_train, y_train)}\n",
    "        print(self.metrics)\n",
    "        return self.metrics\n",
    "\n",
    "    def weights(self):\n",
    "        if len(self.lm.coef_) == 1:\n",
    "            # if there are two concepts, there is only one label.\n",
    "            # We split it in two.\n",
    "            return torch.tensor(np.array([-1 * self.lm.coef_[0], self.lm.coef_[0]])).to('cuda')\n",
    "        else:\n",
    "            return torch.tensor(self.lm.coef_).to('cuda')\n",
    "\n",
    "    def classes(self):\n",
    "        return self.lm.classes_\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model_name, experimental_set_rand):\n",
    "    # Set model\n",
    "    model = models.alexnet()\n",
    "    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    model = model.eval().to(device)\n",
    "\n",
    "    # Layers, classifier and experimental sets\n",
    "    layers = ['classifier.4']\n",
    "    classifier = CustomClassifier()\n",
    "    \n",
    "    # TCAV\n",
    "    mytcav = BTCAV(model=model,\n",
    "                    layers=layers,\n",
    "                    classifier=classifier,\n",
    "                    n_samples=1000,\n",
    "                    layer_attr_method = None\n",
    "                )\n",
    "\n",
    "    # Class tensors\n",
    "    blocked_images = load_image_tensors('blocked')\n",
    "    blocked_tensor = torch.stack([img for img in blocked_images]).to(device)\n",
    "\n",
    "    # Scores\n",
    "    scores = mytcav.interpret(\n",
    "        inputs=blocked_tensor,\n",
    "        experimental_sets=experimental_set_rand,\n",
    "        target=0,\n",
    "    )\n",
    "\n",
    "    tcav_classifier_accuracy = mytcav.classifier.get_metrics()['accs']\n",
    "\n",
    "    ex_sets, cons, vals = extract_btcav_scores(experimental_set_rand, scores, layers)\n",
    "\n",
    "    # Clear the memory\n",
    "    del model, mytcav, classifier\n",
    "    gc.collect()\n",
    "    remove_cav_folder()\n",
    "\n",
    "    return ex_sets, cons, vals, tcav_classifier_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set concepts\n",
    "dark_concept = assemble_concept(\"dark\", 0)\n",
    "light_concept = assemble_concept(\"light\", 1)\n",
    "orange_concept = assemble_concept(\"orange\", 2)\n",
    "d30_concept = assemble_concept(\"distance 30\", 3)\n",
    "d45_concept = assemble_concept(\"distance 45\", 4)\n",
    "d60_concept = assemble_concept(\"distance 60\", 5)\n",
    "random_0_concept = assemble_concept(\"random\", 6)\n",
    "\n",
    "experimental_set_rand = [\n",
    "                         [dark_concept, random_0_concept],\n",
    "                         [light_concept, random_0_concept],\n",
    "                         [orange_concept, random_0_concept],\n",
    "                         [dark_concept, light_concept], \n",
    "                         [dark_concept, orange_concept], \n",
    "                         [light_concept, orange_concept],\n",
    "                         [d30_concept, random_0_concept], \n",
    "                         [d45_concept, random_0_concept], \n",
    "                         [d60_concept, random_0_concept], \n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/full finetuned models/alexnet_finetuned_100_epochs.pth' # Replace this with your model path\n",
    "data = {}\n",
    "\n",
    "for i, exp_set in enumerate(experimental_set_rand):\n",
    "    print(f\"Experiment {i+1}/{len(experimental_set_rand)}\")\n",
    "    exp_set = [exp_set]\n",
    "\n",
    "    ex_sets, cons, vals, tcav_accuracy = get_scores(model_name, exp_set)\n",
    "\n",
    "    vals_list = []\n",
    "    vals_list.append(vals)\n",
    "    vals_list = np.array(vals_list)[0,:,:,0]\n",
    "\n",
    "    data[i] = {\n",
    "        \"experimental_set\": ex_sets,\n",
    "        \"concepts\": cons,\n",
    "        \"tcav_classifier_accuracy\": tcav_accuracy,\n",
    "        \"tcav_avg\": list(np.mean(vals_list, axis=1)),\n",
    "        \"tcav_std\": list(np.std(vals_list, axis=1)),\n",
    "        \"tcav_upper_bound\": list(np.percentile(vals_list, 75, axis=1)),\n",
    "        \"tcav_lower_bound\": list(np.percentile(vals_list, 25, axis=1)),\n",
    "        \"tcav_median\": list(np.median(vals_list, axis=1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "with open(f'results/full finetuned.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
